<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>An Exploration of AI Assistants &amp; Gender - DH 150 Mini-Assignment 1</title><meta name="description" content="Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html"><link rel="alternate" type="application/atom+xml" href="https://nishamcnealis.github.io/DH150_project/feed.xml"><link rel="alternate" type="application/json" href="https://nishamcnealis.github.io/DH150_project/feed.json"><meta property="og:title" content="An Exploration of AI Assistants & Gender"><meta property="og:image" content="https://nishamcnealis.github.io/DH150_project/media/posts/1/Screen-Shot-2022-10-18-at-9.00.51-AM.png"><meta property="og:site_name" content="DH 150 Mini-Assignment 1"><meta property="og:description" content="Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber&hellip;"><meta property="og:url" content="https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://nishamcnealis.github.io/DH150_project/media/website/Screen-Shot-2022-10-15-at-5.43.53-PM-2.png" type="image/x-icon"><link rel="stylesheet" href="https://nishamcnealis.github.io/DH150_project/assets/css/style.css?v=a1172f7828d96554eca4f84bc4b2d7dc"><link rel="stylesheet" href="https://nishamcnealis.github.io/DH150_project/assets/css/photoswipe.css?v=357f87f4e9502a5318d89e8e76e0a344"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html"},"headline":"An Exploration of AI Assistants & Gender","datePublished":"2022-10-15T17:39","dateModified":"2022-10-18T10:08","image":{"@type":"ImageObject","url":"https://nishamcnealis.github.io/DH150_project/media/posts/1/Screen-Shot-2022-10-18-at-9.00.51-AM.png","height":726,"width":1438},"description":"Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber&hellip;","author":{"@type":"Person","name":"Nisha McNealis","url":"https://nishamcnealis.github.io/DH150_project/authors/nisha-mcnealis/"},"publisher":{"@type":"Organization","name":"Nisha McNealis"}}</script><style>.pswp--svg .pswp__button,
				          .pswp--svg .pswp__button--arrow--left:before,
				          .pswp--svg .pswp__button--arrow--right:before {
					          background-image: url(https://nishamcnealis.github.io/DH150_project/assets/svg/gallery-icons-light.svg);
			              }</style></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://nishamcnealis.github.io/DH150_project/">DH 150 Mini-Assignment 1</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li class="active"><a href="https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html" target="_self">Home</a></li><li><a href="https://nishamcnealis.github.io/DH150_project/about.html" target="_self">About</a></li></ul></nav></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://nishamcnealis.github.io/DH150_project/media/posts/1/Screen-Shot-2022-10-18-at-9.00.51-AM.png" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-9.00.51-AM-xs.png 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-9.00.51-AM-sm.png 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-9.00.51-AM-md.png 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-9.00.51-AM-lg.png 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-9.00.51-AM-xl.png 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-9.00.51-AM-2xl.png 1600w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" height="726" width="1438" alt=""></figure><header class="hero__content"><div class="wrapper"><h1>An Exploration of AI Assistants &amp; Gender</h1></div></header></div><div class="wrapper post__entry"><p><span style="font-weight: 400;">Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber people.</span></p><p><span style="font-weight: 400;">As these technologies become more and more advanced, we should think critically about their societal impacts. In this site, we'll explore how developers’ efforts to feminize, and by extension, personify, virtual assistants will continue to create a less equitable, more dangerous world for women.</span></p><h2>Background</h2><p><span style="font-weight: 400;">VAs are perceived as unmistakably female.</span></p><p><span style="font-weight: 400;">Siri, Alexa, Google Assistant, and Cortana were all initially released with default female voices. Apple recently made the switch to a gender-neutral default voice, but it’s hard to argue that “Siri” is genderless when the name itself is Norse for “beautiful woman who leads you to victory.”</span></p><figure class="post__image"><figure class="post__image post__image--center"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2.webp" sizes="100vw" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2-xs.webp 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2-sm.webp 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2-md.webp 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2-lg.webp 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2-xl.webp 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/i6RCrms6Fe78AcBlnF1bZnB4vXY7mAIS4N6fgiurhi0-2-2xl.webp 1600w" alt="If you think that’s bad, “Cortana” is a reference to a highly sexualized female character in the video game Halo." width="1920" height="1080"></figure><figcaption><span style="font-weight: 400;">If you think th</span><span style="font-weight: 400;">at’s bad, “Cortana” is a reference to a highly sexualized female character in the video game Halo. Photo: https://halo.fandom.com/wiki/Cortana</span></figcaption></figure><p><span style="font-weight: 400;">Wired reporter Jessi Hempel notes, “we assign female pronouns to them, and in turn, they fold feminine turns of phrase into their robotic and occasionally inane answers to our requests.”</span></p><p><span style="font-weight: 400;">This pattern is not exclusive to AI assistants — we also hear female voices in everything from GPS navigation to voicemail systems to public transport announcements. There are several reasons behind the feminization of computerized systems. Check out these slides to learn more.</span></p><div class="post__iframe"><iframe loading="lazy" width="960" height="569" style="width: 862px; height: 511px;" src="https://docs.google.com/presentation/d/e/2PACX-1vSp0Z0ZqVwjTHxCd-Cw9i22FxccDfHeqqHoVjQVa5JaXA9C-eHy6WrzOHsXP5J3CiCwz5kmpRvf5L1N/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder="0" allowfullscreen="allowfullscreen" mozallowfullscreen="mozallowfullscreen" webkitallowfullscreen="webkitallowfullscreen"></iframe></div><h2>Case Studies</h2><p>Try out this interactive activity to learn about two chatbots that are especially relevant to this discussion.</p><figure class="post__image"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/Screen-Shot-2022-10-18-at-8.54.18-AM.png" sizes="100vw" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.54.18-AM-xs.png 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.54.18-AM-sm.png 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.54.18-AM-md.png 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.54.18-AM-lg.png 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.54.18-AM-xl.png 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.54.18-AM-2xl.png 1600w" alt="" width="1136" height="266"></figure><p class="align-center"><button style="all: unset; font-family: Helvetica,Arial,sans-serif; display: inline-block; max-width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-color: #a87db7; color: #ffffff; font-size: 20px; border-radius: 25px; padding: 0 33px; font-weight: bold; height: 50px; cursor: pointer; line-height: 50px; text-align: center; margin: 0; text-decoration: none;" data-tf-popup="LTmjbiRH" data-tf-size="100">Try me!</button><script src="//embed.typeform.com/next/embed.js"></script></p><hr><h2>Ethical Concerns</h2><p><span style="font-weight: 400;">VA creators have argued that their products should not be considered human-like at all. Amazon’s branding guidelines claim “Alexa isn’t a person, but has a persona – Amazon personifies Alexa as an artificial intelligence (AI) and not as a person with a physical body or a gender identity.” And Apple’s style guide specifies “Do not refer to Siri with pronouns such as ‘she,’ ‘him,’ or ‘her.’ Depending on language support, Siri may offer a male or female voice, or both.”</span></p><p><span style="font-weight: 400;">In practice, however, voice assistants are frequently anthropomorphized and sexualized. An analysis of Amazon.com user reviews of the Echo device, which uses Alexa, found that more than 30% participated in some personification of the product. 13.6% used the name “Alexa” with pronouns like “she” and “her” and over 2,000 reviewers compared Alexa to a companion, girlfriend, wife, secretary, or family member (Gao 2018). In a 2015 survey of 12,000 digital assistant users, 39% claimed that they would fall in love with a voice assistant if it could love them back (API.ai, 2015).</span></p><p><span style="font-weight: 400;">The widespread adoption of virtual assistants, particularly female-presenting ones, raises a variety of ethical concerns.</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">1. Manufacturing Human Connection</span></h4><p><span style="font-weight: 400;">According to a 2018 study, users can be aware that AI assistants are not sentient and still implicitly view them as humanoid — people responded with signs of stress when asked to switch off a robot with a computerized voice that was begging them not to. The researchers wrote, “due to their social nature, people will rather make the mistake of treating something falsely as human than treating something falsely as non-human.” </span>  </p><div class="gallery-wrapper"><div class="gallery" data-is-empty="false" data-translation="Add images" data-columns="3"><figure class="gallery__item"><a href="https://nishamcnealis.github.io/DH150_project/media/posts/1/gallery/tumblr_oftwwwYhHD1vvi3bvo2_250.gif" data-size="245x150"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/gallery/tumblr_oftwwwYhHD1vvi3bvo2_250.gif" alt=""></a></figure><figure class="gallery__item"><a href="https://nishamcnealis.github.io/DH150_project/media/posts/1/gallery/anigif_sub-buzz-672-1567719102-2-2.gif" data-size="268x177"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/gallery/anigif_sub-buzz-672-1567719102-2-2.gif" alt=""></a></figure><figure class="gallery__item"><a href="https://nishamcnealis.github.io/DH150_project/media/posts/1/gallery/smile-delight.gif" data-size="498x278"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/gallery/smile-delight.gif" alt=""></a></figure></div></div><p class="msg--info msg"><em>Watchers of The Good Place might recognize this running joke in which human characters struggle to reboot a humanoid personal assistant named Janet.</em></p><p><span style="font-weight: 400;">These results are exacerbated when gender comes into play. A 2021 meta-analysis of four studies found that “using implicit, subtle, and blatant scales of humanness, our results consistently show that women (Studies 1A and 1B), female bots (Studies 2 and 3), and female chatbots (Study 4) are perceived as more human than their male counterparts when compared with non-human entities” (Borau, 2021). Women are more often socialized to be loving, nurturing, and kind, while men are raised to be forceful, assertive, and competent. The researchers theorize that “because warmth and experience (but not competence) are seen as fundamental qualities to be a full human but are lacking in machines, we argue that people prefer female bots because they are perceived as more human than male bots [...] These results highlight the ethical quandary faced by AI designers and policymakers: Women are said to be transformed into objects in AI, but injecting women's humanity into AI objects makes these objects seem more human and acceptable” (Borau, 2021).</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">2. Perpetuation of Misogyny</span></h4><p><span style="font-weight: 400;">It might seem dystopian to imagine a world in which robots meet all our social needs, but virtual assistants might reach this point sooner than we expect. Sites like Invisible Girlfriend and games like LovePlus already simulate relationships online. Are virtual partners healthy, and could they impede our ability to form genuine human connections? Johanna Blakley of the Norman Lear Centre points out that “humans have always used games, play and story time to create simulations of important life experiences: it gives us a chance to practice and to vicariously experience new and strange things in a relatively safe environment.” </span></p><p><span style="font-weight: 400;">But what if these “new and strange things” are offensive, immoral, or illegal? This is where the feminization of voice assistants becomes especially relevant. A United Nations report explained, “the assistant holds no power of agency beyond what the commander asks of it. It honours commands and responds to queries regardless of their tone or hostility. In many communities, this reinforces commonly held gender biases that women are subservient and tolerant of poor treatment.” Implicit sexism toward voice assistants may not be confined to a “safe environment” — it may instead encourage sexist attitudes toward real women.</span></p><figure class="post__image post__image--center"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/Screen-Shot-2022-10-18-at-8.38.33-AM.png" sizes="100vw" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.38.33-AM-xs.png 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.38.33-AM-sm.png 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.38.33-AM-md.png 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.38.33-AM-lg.png 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.38.33-AM-xl.png 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.38.33-AM-2xl.png 1600w" alt="" width="676" height="379"></figure><p><span style="font-weight: 400;">And it’s not just adults who are using thes</span><span style="font-weight: 400;">e devices — products like Echo and Google Home are intended to provide services for the entire household. This means that by design, developing children may observe or participate in the mistreatment of female AI assistants. Guardian reporter Amelia Hill writes, “The rapid rise in voice assistants [could] have a long-term impact on children’s social and cognitive development, specifically their empathy, compassion and critical thinking skills.”</span></p><p><span style="font-weight: 400;">According to writer and technologist Gideon Rosenblatt, “as digital assistants become increasingly human-like, it’s not unreasonable to suspect that toxic behavior habits with these relationships could spread to our relationships with people. This is particularly true when there are absolutely no negative consequences for our abusive behavior.”</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">3. Exacerbated Impacts on Marginalized Groups</span></h4><p><span style="font-weight: 400;">Each of these issues can and should be analyzed through an intersectional lens.</span></p><figure class="post__image post__image--center"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/Screen-Shot-2022-10-18-at-8.55.54-AM.png" sizes="100vw" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.55.54-AM-xs.png 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.55.54-AM-sm.png 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.55.54-AM-md.png 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.55.54-AM-lg.png 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.55.54-AM-xl.png 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/Screen-Shot-2022-10-18-at-8.55.54-AM-2xl.png 1600w" alt="" width="674" height="379"></figure><p><span style="font-weight: 400;">It is not an accident that our media chooses white women to portray representations of virtual assistants. Plus, white dialects are used for computerized voices in the real world. As cultural theorist Mladen Dolar put it, the vocal norm used by these machines is “an accent which has been declared a non-accent.” And even when voice assistants offer stereotypically male voices in addition to female ones, these options reinforce the gender binary. </span></p><h2>Conclusion</h2><p><span style="font-weight: 400;">It is too late to avoid the adoption of virtual assistants, but there are several potential solutions that have been suggested to mitigate their negative effects.</span></p><p><span style="font-weight: 400;">Creators of these technologies have taken steps to reduce bias. Google’s DeepMind is working on a new text-to-speech algorithm that requires less data, which would increase accuracy for male voice assistants. Google also now randomly assigns new users to a male or female default voice. Vox reporter Sigal Samuel notes, “Some companies, facing criticism in the media over the past couple of years, have made modest strides[...] Siri no longer responds to ‘You’re a bitch’ with ‘I’d blush if I could’ — she now says, ‘I don’t know how to respond to that.’ And Alexa now replies to some sexually explicit queries by saying, ‘I’m not sure what outcome you expected.’” Plus, tech companies are gradually becoming more diverse, more transparent with their data and more upfront about any potential biases.</span></p><p><span style="font-weight: 400;">Brand new technologies are also emerging to compete with our current tools. <a href="https://www.genderlessvoice.com/">Q is a voice assistant unveiled in 2019</a> as the first completely gender-neutral alternative.</span></p><blockquote><p><span style="font-weight: 400;">"One of our big goals with Q was to contribute to a global conversation about gender, and about gender and technology and ethics, and how to be inclusive for people that identify in all sorts of different ways.”</span></p><p>- Q Developer J<span style="font-weight: 400;">ulie Carpenter</span></p></blockquote><p><span style="font-weight: 400;">A nonprofit called Feminist Internet released their Personal Intelligent Assistant Standards and Feminist Chatbot Design Process, both of which provide guidelines for designers who want to create more equitable VAs. They also came out with this feminist chatbot called F’xa intended to educate users about their biases. </span></p><div class="post__iframe"><iframe loading="lazy" width="640" height="400" src="https://player.vimeo.com/video/333187497?h=4c7bdcd479&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></div><p><span style="font-weight: 400;">That said, major players in the voice assistant industry will always motivated by financial gain, not kindness or goodwill. Those who demand changes to the current technologies emphasize that pressure has to come from consumers — and at the rate we’re progressing, it has to come soon.</span></p></div><footer class="wrapper post__footer"><div class="post__share"></div><div class="post__bio bio"><img src="https://nishamcnealis.github.io/DH150_project/media/website/IMG_7629-2.jpg" loading="lazy" height="1154" width="1149" class="bio__avatar" alt="Nisha McNealis"><div class="bio__info"><h3 class="bio__name"><a href="https://nishamcnealis.github.io/DH150_project/authors/nisha-mcnealis/" rel="author">Nisha McNealis</a></h3><p>Nisha is a fourth-year computer science major at UCLA.</p></div></div></footer></article></main><footer class="footer"><div class="footer__copyright"><p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img style="border-width: 0;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" alt="Creative Commons License"></a><br>Alexa, play (“An Exploration of AI Assistants from a Feminist Standpoint”) is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://nishamcnealis.github.io/DH150_project/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://nishamcnealis.github.io/DH150_project/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');

        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script><script defer="defer" src="https://nishamcnealis.github.io/DH150_project/assets/js/photoswipe.min.js?v=017385b552f7e0d979e2e2fe6f324015"></script><script defer="defer" src="https://nishamcnealis.github.io/DH150_project/assets/js/photoswipe-ui-default.min.js?v=d067f0883540b1ddda0e2c9ad1b14260"></script><script>var initPhotoSwipeFromDOM=function(gallerySelector){var parseThumbnailElements=function(el){var thumbElements=el.childNodes,numNodes=thumbElements.length,items=[],figureEl,linkEl,size,item;for(var i=0;i<numNodes;i++){figureEl=thumbElements[i];if(figureEl.nodeType!==1){continue;}
          linkEl=figureEl.children[0];size=linkEl.getAttribute('data-size').split('x');item={src:linkEl.getAttribute('href'),w:parseInt(size[0],10),h:parseInt(size[1],10)};if(figureEl.children.length>1){item.title=figureEl.children[1].innerHTML;}
          if(linkEl.children.length>0){item.msrc=linkEl.children[0].getAttribute('src');}
          item.el=figureEl;items.push(item);}
          return items;};var closest=function closest(el,fn){return el&&(fn(el)?el:closest(el.parentNode,fn));};var onThumbnailsClick=function(e){e=e||window.event;e.preventDefault?e.preventDefault():e.returnValue=false;var eTarget=e.target||e.srcElement;var clickedListItem=closest(eTarget,function(el){return(el.tagName&&el.tagName.toUpperCase()==='FIGURE');});if(!clickedListItem){return;}
          var clickedGallery=clickedListItem.parentNode,childNodes=clickedListItem.parentNode.childNodes,numChildNodes=childNodes.length,nodeIndex=0,index;for(var i=0;i<numChildNodes;i++){if(childNodes[i].nodeType!==1){continue;}
          if(childNodes[i]===clickedListItem){index=nodeIndex;break;}
          nodeIndex++;}
          if(index>=0){openPhotoSwipe(index,clickedGallery);}
          return false;};var photoswipeParseHash=function(){var hash=window.location.hash.substring(1),params={};if(hash.length<5){return params;}
          var vars=hash.split('&');for(var i=0;i<vars.length;i++){if(!vars[i]){continue;}
          var pair=vars[i].split('=');if(pair.length<2){continue;}
          params[pair[0]]=pair[1];}
          if(params.gid){params.gid=parseInt(params.gid,10);}
          return params;};var openPhotoSwipe=function(index,galleryElement,disableAnimation,fromURL){var pswpElement=document.querySelectorAll('.pswp')[0],gallery,options,items;items=parseThumbnailElements(galleryElement);options={galleryUID:galleryElement.getAttribute('data-pswp-uid'),getThumbBoundsFn:function(index){var thumbnail=items[index].el.getElementsByTagName('img')[0],pageYScroll=window.pageYOffset||document.documentElement.scrollTop,rect=thumbnail.getBoundingClientRect();return{x:rect.left,y:rect.top+pageYScroll,w:rect.width};},
          mainClass:'pswp--dark',
          preload: [1,2],
          hideAnimationDuration:200,
          showAnimationDuration:0,
          bgOpacity: 0.7,
          showHideOpacity:true,
          closeOnScroll: true,
          arrowKeys: true,
          closeEl: true,
          captionEl: true,
          fullscreenEl: true,
          zoomEl: true,
          shareEl: true,
          counterEl: true,
          arrowEl: true,
          preloaderEl: true
          };if(fromURL){if(options.galleryPIDs){for(var j=0;j<items.length;j++){if(items[j].pid==index){options.index=j;break;}}}else{options.index=parseInt(index,10)-1;}}else{options.index=parseInt(index,10);}
          if(isNaN(options.index)){return;}
          if(disableAnimation){options.showAnimationDuration=0;}
          gallery=new PhotoSwipe(pswpElement,PhotoSwipeUI_Default,items,options);gallery.init();gallery.options.escKey=true;};var galleryElements=document.querySelectorAll(gallerySelector);for(var i=0,l=galleryElements.length;i<l;i++){galleryElements[i].setAttribute('data-pswp-uid',i+1);galleryElements[i].onclick=onThumbnailsClick;}
          var hashData=photoswipeParseHash();if(hashData.pid&&hashData.gid){openPhotoSwipe(hashData.pid,galleryElements[hashData.gid-1],true,true);}};window.addEventListener('load', function () {initPhotoSwipeFromDOM('.gallery');}, false);</script><div class="pswp" tabindex="-1" role="dialog" aria-hidden="true"><div class="pswp__bg"></div><div class="pswp__scroll-wrap"><div class="pswp__container"><div class="pswp__item"></div><div class="pswp__item"></div><div class="pswp__item"></div></div><div class="pswp__ui pswp__ui--hidden"><div class="pswp__top-bar"><div class="pswp__counter"></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button><button class="pswp__button pswp__button--share" title="Share"></button><button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button><button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class="pswp__preloader"><div class="pswp__preloader__icn"><div class="pswp__preloader__cut"><div class="pswp__preloader__donut"></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class="pswp__share-tooltip"></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button><button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class="pswp__caption"><div class="pswp__caption__center"></div></div></div></div></div></body></html>