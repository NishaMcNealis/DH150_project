<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Alexa, play (“An Exploration of AI Assistants from a Feminist Standpoint”) - DH 150 Mini-Assignment 1</title><meta name="description" content="Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html"><link rel="alternate" type="application/atom+xml" href="https://nishamcnealis.github.io/DH150_project/feed.xml"><link rel="alternate" type="application/json" href="https://nishamcnealis.github.io/DH150_project/feed.json"><meta property="og:title" content="Alexa, play (“An Exploration of AI Assistants from a Feminist Standpoint”)"><meta property="og:image" content="https://nishamcnealis.github.io/DH150_project/media/posts/1/undraw_voice_control_ofo1.png"><meta property="og:site_name" content="DH 150 Mini-Assignment 1"><meta property="og:description" content="Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber&hellip;"><meta property="og:url" content="https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://nishamcnealis.github.io/DH150_project/media/website/Screen-Shot-2022-10-15-at-5.43.53-PM-2.png" type="image/x-icon"><link rel="stylesheet" href="https://nishamcnealis.github.io/DH150_project/assets/css/style.css?v=64f6c0816c4b27860459d9676ddafe58"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html"},"headline":"Alexa, play (“An Exploration of AI Assistants from a Feminist Standpoint”)","datePublished":"2022-10-15T17:39","dateModified":"2022-10-17T13:38","image":{"@type":"ImageObject","url":"https://nishamcnealis.github.io/DH150_project/media/posts/1/undraw_voice_control_ofo1.png","height":991,"width":1213},"description":"Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber&hellip;","author":{"@type":"Person","name":"Nisha McNealis","url":"https://nishamcnealis.github.io/DH150_project/authors/nisha-mcnealis/"},"publisher":{"@type":"Organization","name":"Nisha McNealis"}}</script></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://nishamcnealis.github.io/DH150_project/">DH 150 Mini-Assignment 1</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li class="active"><a href="https://nishamcnealis.github.io/DH150_project/alexa-play-an-exploration-of-ai-assistants-from-a-feminist-standpoint-by-nisha-mcnealis.html" target="_self">Home</a></li></ul></nav></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://nishamcnealis.github.io/DH150_project/media/posts/1/undraw_voice_control_ofo1.png" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/undraw_voice_control_ofo1-xs.png 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/undraw_voice_control_ofo1-sm.png 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/undraw_voice_control_ofo1-md.png 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/undraw_voice_control_ofo1-lg.png 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/undraw_voice_control_ofo1-xl.png 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/undraw_voice_control_ofo1-2xl.png 1600w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" height="991" width="1213" alt=""></figure><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2022-10-15T17:39">October 15, 2022</time></div><h1>Alexa, play (“An Exploration of AI Assistants from a Feminist Standpoint”)</h1><div class="post__meta post__meta--author"><a href="https://nishamcnealis.github.io/DH150_project/authors/nisha-mcnealis/" class="feed__author">Nisha McNealis</a></div></div></header></div><div class="wrapper post__entry"><p><span style="font-weight: 400;">Voice assistants (VAs) are quickly becoming a predominant feature of everything from our smartphones to our cars to our kitchen devices. We're increasingly reliant on them for communication with others, scheduling, home maintenance, and even companionship. By 2024, digital voice assistants are expected to outnumber people!</span></p><figure class="post__image"><figure class="post__image post__image--center"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/voice-assistants-in-use-fi.png" sizes="100vw" srcset="https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/voice-assistants-in-use-fi-xs.png 300w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/voice-assistants-in-use-fi-sm.png 480w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/voice-assistants-in-use-fi-md.png 768w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/voice-assistants-in-use-fi-lg.png 1024w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/voice-assistants-in-use-fi-xl.png 1360w, https://nishamcnealis.github.io/DH150_project/media/posts/1/responsive/voice-assistants-in-use-fi-2xl.png 1600w" alt="" width="401" height="267"></figure><figcaption>Graph of voice assistants in use over time by <a href="https://voicebot.ai/2019/02/14/juniper-estimates-3-25-billion-voice-assistants-are-in-use-today-google-has-about-30-of-them/">Voicebot.ai</a></figcaption></figure><p><span style="font-weight: 400;">As these technologies become more and more advanced, we should think critically about their societal impacts. In this site, we'll explore how developers’ efforts to feminize, and by extension, personify, virtual assistants will continue to create a less equitable, more dangerous world for women.</span></p><h2>Background</h2><p><span style="font-weight: 400;">VAs are perceived as unmistakably female. Siri, Alexa, Google Assistant, and Cortana were all initially released with default female voices. Apple recently made the switch to a gender-neutral default voice, but it’s hard to argue that “Siri” is genderless when the name itself is Norse for “beautiful woman who leads you to victory.”</span></p><figure class="post__image post__image--right"><img loading="lazy" style="margin-bottom: 1.37143rem; margin-left: 1.37143rem; outline: 3px solid rgba(var(--color-primary-rgb), 0.55)  !important;" src="file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/Cortana_h5-2.png" sizes="100vw" srcset="file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/responsive/Cortana_h5-2-xs.png 300w, file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/responsive/Cortana_h5-2-sm.png 480w, file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/responsive/Cortana_h5-2-md.png 768w, file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/responsive/Cortana_h5-2-lg.png 1024w, file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/responsive/Cortana_h5-2-xl.png 1360w, file:///Users/nisha_mcnealis/Documents/Publii/sites/dh-150-mini-assignment-1/input/media/posts/2/responsive/Cortana_h5-2-2xl.png 1600w" alt="Image of Cortana from https://time.com/48123/microsofts-cortana-raises-important-questions-about-sexism-and-gender-stereotyping/" width="161" height="310"><figcaption>Image of Cortana from Time Maganzine</figcaption></figure><p><span style="font-weight: 400;">If you think th</span><span style="font-weight: 400;">at’s bad, “Cortana” is a reference to a highly sexualized female character in the video game Halo.</span></p><p><span style="font-weight: 400;">Wired reporter Jessi Hempel notes, “we assign female pronouns to them, and in turn, they fold feminine turns of phrase into their robotic and occasionally inane answers to our requests.”</span></p><p><span style="font-weight: 400;">This pattern is not exclusive to AI assistants — we also hear female voices in everything from GPS navigation to voicemail systems to public transport announcements. There are several reasons behind the feminization of computerized systems. </span></p><h4 class="msg--highlight"><span style="font-weight: 400;">1. Gender Norms in the Workplace</span></h4><p><span style="font-weight: 400;">First, female voice assistants reflect traditional gender norms in the workplace. Voice assistants are designed to make calls, provide information, schedule meetings, and set reminders just like any personal assistant. According to DataUSA, 94.7% of secretaries and administrative assistants are female. This discrepancy has existed for the last seventy years, starting when women first began to enter the workplace in large numbers. A 2016 study found that personal assistant bots were almost entirely female, while bots in male-dominated spheres like law or finance were overwhelmingly male. </span></p><h4 class="msg--highlight"><span style="font-weight: 400;">2. Societal Perception of Female Voices</span></h4><p><span style="font-weight: 400;">In addition, many believe that female voices are preferred over male voices. Studies have shown that female voices are perceived as warmer, more trustworthy, and less forceful. As voice-acting content creator Flor Zaccagnino reasoned,</span></p><blockquote><p><span style="font-weight: 400;">“Female voices make users feel as if technology is being helpful; it solves their problems for them in a soothing, non-confrontational way. Male voices can be perceived as commanding; telling users what to do instead of pointing out solutions.”</span></p></blockquote><p><span style="font-weight: 400;">Stanford professor Clifford Nass argues that our comfort with female voices can be traced back to the womb, since fetuses have been shown to recognize their mother’s voice but not their father’s. It is worth noting that a lot of the research suggesting that people favor female voices has been challenged by anecdotal findings. Women are often criticized for “upspeak” (a tendency to raise the pitch of their voices at the end of sentences), vocal fry, and filler words. Female radio hosts have been described as “shrill” and “nasal” since the 1920s, and female public figures like Margaret Thatcher and Elizabeth Holmes have been known to purposefully make their voices deeper and more masculine so as to be taken seriously. But regardless of whether the studies mentioned are valid or not, they might have played a role in developers’ decisions to create female VAs.</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">3. Media Portrayal of VAs</span></h4><p><span style="font-weight: 400;">Yet another reason behind this phenomenon lies in the media’s portrayal of male versus female AI. The 1968 movie </span><i><span style="font-weight: 400;">2001: A Space Odessey </span></i><span style="font-weight: 400;">featured a malicious voice assistant called HAL 9000, voiced by a man. Silicon Valley analyst Tim Bajarin theorized that “a lot of tech companies strayed away from the male voice because of HAL.”</span></p><div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/oR_e9y-bka0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></div><p><span style="font-weight: 400;">In contrast, depictions of female voice assistants have typically shown AI systems serving men, often in a sexual way. The 2013 Oscar-nominated movie </span><i><span style="font-weight: 400;">Her </span></i><span style="font-weight: 400;">is a prime example: the main character falls in love with a friendly, flirtatious virtual assistant named Samantha.</span></p><div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/ne6p6MfLBxc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></div><p><span style="font-weight: 400;">It is much easier to put users at ease when a company is pitching a version of Samantha, not a version of HAL.</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">4. Technological Challeges</span></h4><p><span style="font-weight: 400;">Finally, it may be technologically easier to build female assistants because female voices are overrepresented in the datasets used to build our AI systems. Since the 1880s, telephone operators have been almost exclusively female, meaning we have hundreds of years of female audio recordings to train new text-to-speech models on. In fact, Google originally tried to launch “Google Assistant” with both a male and a female voice, but the performance of the male system was significantly worse because it was trained on less data. The company squashed the male version and released the female one only. However, this viewpoint has also been contested — Johan Wouters from the text-to-speech company Cerence said, “we can build very high-quality voices for both genders, and in my view, the ease of development is not the main factor here.”</span></p><h2>Ethical Concerns</h2><p><span style="font-weight: 400;">VA creators have argued that their products should not be considered human-like at all. Amazon’s branding guidelines claim “Alexa isn’t a person, but has a persona – Amazon personifies Alexa as an artificial intelligence (AI) and not as a person with a physical body or a gender identity.” And Apple’s style guide specifies “Do not refer to Siri with pronouns such as ‘she,’ ‘him,’ or ‘her.’ Depending on language support, Siri may offer a male or female voice, or both.”</span></p><p><span style="font-weight: 400;">In practice, however, voice assistants are frequently anthropomorphized and sexualized. An analysis of Amazon.com user reviews of the Echo device, which uses Alexa, found that more than 30% participated in some personification of the product. 13.6% used the name “Alexa” with pronouns like “she” and “her” and over 2,000 reviewers compared Alexa to a companion, girlfriend, wife, secretary, or family member (Gao 2018). In a 2015 survey of 12,000 digital assistant users, 39% claimed that they would fall in love with a voice assistant if it could love them back (API.ai, 2015).</span></p><p><span style="font-weight: 400;">The widespread adoption of virtual assistants, particularly female-presenting ones, raises a variety of ethical concerns.</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">1. Manufacturing Human Connection</span></h4><p><span style="font-weight: 400;">According to a 2018 study, users can be aware that AI assistants are not sentient and still implicitly view them as humanoid — people responded with signs of stress when asked to switch off a robot with a computerized voice that was begging them not to. The researchers wrote, “due to their social nature, people will rather make the mistake of treating something falsely as human than treating something falsely as non-human.” </span></p><figure class="post__image align-center"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/anigif_sub-buzz-672-1567719102-2.gif" alt="" width="312" height="206"></figure> <figure class="post__image align-center"><img loading="lazy" src="https://nishamcnealis.github.io/DH150_project/media/posts/1/tumblr_oftwwwYhHD1vvi3bvo2_250-3.gif" alt="" width="335" height="205"></figure><address> </address><address><span style="font-weight: 400;">Watchers of The Good Place might recognize this running joke in which human characters struggle to reboot a humanoid personal assistant named Janet.</span></address><p><span style="font-weight: 400;">These results are exacerbated when gender comes into play. A 2021 meta-analysis of four studies found that “using implicit, subtle, and blatant scales of humanness, our results consistently show that women (Studies 1A and 1B), female bots (Studies 2 and 3), and female chatbots (Study 4) are perceived as more human than their male counterparts when compared with non-human entities” (Borau, 2021). Women are more often socialized to be loving, nurturing, and kind, while men are raised to be forceful, assertive, and competent. The researchers theorize that “because warmth and experience (but not competence) are seen as fundamental qualities to be a full human but are lacking in machines, we argue that people prefer female bots because they are perceived as more human than male bots [...] These results highlight the ethical quandary faced by AI designers and policymakers: Women are said to be transformed into objects in AI, but injecting women's humanity into AI objects makes these objects seem more human and acceptable” (Borau, 2021).</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">2. Perpetuation of Misogyny</span></h4><p><span style="font-weight: 400;">It might seem dystopian to imagine a world in which robots meet all our social needs, but virtual assistants might reach this point sooner than we expect. Sites like Invisible Girlfriend and games like LovePlus already simulate relationships online. Are virtual partners healthy, and could they impede our ability to form genuine human connections? Johanna Blakley of the Norman Lear Centre points out that “humans have always used games, play and story time to create simulations of important life experiences: it gives us a chance to practice and to vicariously experience new and strange things in a relatively safe environment.” </span></p><p><span style="font-weight: 400;">But what if these “new and strange things” are offensive, immoral, or illegal? This is where the feminization of voice assistants becomes especially relevant. A United Nations report explained, “the assistant holds no power of agency beyond what the commander asks of it. It honours commands and responds to queries regardless of their tone or hostility. In many communities, this reinforces commonly held gender biases that women are subservient and tolerant of poor treatment.” Implicit sexism toward voice assistants may not be confined to a “safe environment” — it may instead encourage sexist attitudes toward real women. There are already recorded differences in the way women treat smart assistants compared to men: 62% of women versus 45% of men use terms like “please” and “thank you” when speaking to VAs. </span></p><p><span style="font-weight: 400;">And it’s not just adults who are using these devices — products like Echo and Google Home are intended to provide services for the entire household. This means that by design, developing children may observe or participate in the mistreatment of female AI assistants. Guardian reporter Amelia Hill writes, “The rapid rise in voice assistants [could] have a long-term impact on children’s social and cognitive development, specifically their empathy, compassion and critical thinking skills.”</span></p><p><span style="font-weight: 400;">According to writer and technologist Gideon Rosenblatt, “as digital assistants become increasingly human-like, it’s not unreasonable to suspect that toxic behavior habits with these relationships could spread to our relationships with people. This is particularly true when there are absolutely no negative consequences for our abusive behavior.”</span></p><h4 class="msg--highlight"><span style="font-weight: 400;">3. Exacerbated Impacts on Marginalized Groups</span></h4><p><span style="font-weight: 400;">Each of these issues can and should be analyzed through an intersectional lens. Ph.D. student Taylor C. Moran writes,</span></p><blockquote><p><span style="font-weight: 400;">“AI VAs [virtual assistants] reflect characteristics of white femininity in voice and cultural configuration for the purposes of white supremacy and capitalistic gain [...]  Such characterization of these technologies is easily apparent in the portrayal of the AI VA in popular culture texts.”</span></p></blockquote><p><span style="font-weight: 400;">It is not an accident that our media chooses white women to portray representations of virtual assistants. Plus, white dialects are used for computerized voices in the real world. As cultural theorist Mladen Dolar put it, the vocal norm used by these machines is “an accent which has been declared a non-accent.” And even when voice assistants offer stereotypically male voices in addition to female ones, these options reinforce the gender binary. </span></p><h2>Case Studies</h2><div style="width: 100%; height: 100%;" data-tf-widget="LTmjbiRH" data-tf-opacity="100" data-tf-chat=""> </div><p><script src="//embed.typeform.com/next/embed.js"></script></p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on October 17, 2022</p><div class="post__share"></div><div class="post__bio bio"><div class="bio__info"><h3 class="bio__name"><a href="https://nishamcnealis.github.io/DH150_project/authors/nisha-mcnealis/" rel="author">Nisha McNealis</a></h3></div></div></footer></article></main><footer class="footer"><div class="footer__copyright"><p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img style="border-width: 0;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" alt="Creative Commons License"></a><br>Alexa, play (“An Exploration of AI Assistants from a Feminist Standpoint”) is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://nishamcnealis.github.io/DH150_project/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://nishamcnealis.github.io/DH150_project/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');

        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>